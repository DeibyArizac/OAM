# Sistema de Profiling - Medici√≥n de Tiempos de Ejecuci√≥n

## Descripci√≥n

El sistema de profiling permite medir con precisi√≥n el tiempo de ejecuci√≥n de cada etapa del procesamiento OAM (Source, Encoder, Channel, Decoder) para an√°lisis de rendimiento y optimizaci√≥n.

## Arquitectura

El sistema de profiling est√° integrado en el pipeline principal y mide autom√°ticamente:

1. **Tiempo total de ejecuci√≥n** del sistema completo
2. **Tiempo por etapa** (Source, Encoder, Channel, Decoder)
3. **Tiempo promedio por s√≠mbolo** procesado
4. **Throughput** del sistema (s√≠mbolos/segundo)
5. **Distribuci√≥n porcentual** del tiempo entre etapas

## Archivos del Sistema

### M√≥dulos Principales

- **`oam_profiler.py`** - M√≥dulo de profiling (medici√≥n de tiempos)
- **`generate_profiling_graphs.py`** - Generador de gr√°ficas visuales
- **`PROFILING_README.md`** - Este documento

### Archivos Modificados

Los siguientes bloques fueron instrumentados con profiling:

- `oam_encoder.py` - Mide tiempo de codificaci√≥n
- `oam_channel.py` - Mide tiempo de propagaci√≥n atmosf√©rica
- `oam_decoder.py` - Mide tiempo de decodificaci√≥n
- `oam_complete_system.py` - Inicia/finaliza profiling total

## Uso

### Ejecuci√≥n Autom√°tica

El profiling se ejecuta **autom√°ticamente** cuando se ejecuta el sistema:

```bash
cd /opt/OAM_System

# Opci√≥n 1: Modo headless (sin GUI)
python3 oam_complete_system.py --headless --config current_run/config_from_grc.json

# Opci√≥n 2: Desde GNU Radio Companion
gnuradio-companion oam_complete_flowgraph.grc
# Luego presionar Run (‚ñ∂)
```

### Ubicaci√≥n de Resultados

Despu√©s de la ejecuci√≥n, los resultados se guardan en:

- **`current_run/profiling_report.json`** - Reporte JSON con todas las m√©tricas
- **Console output** - Resumen impreso en la terminal al finalizar

## Formato del Reporte JSON

```json
{
  "timestamp": "2025-01-27T10:30:15.123456",
  "total_time": 5.234,
  "symbol_count": 42,
  "throughput": 8.02,
  "stages": {
    "source": {
      "total": 0.123,
      "avg": 0.002929,
      "min": 0.002800,
      "max": 0.003100,
      "count": 42,
      "std": 0.000045
    },
    "encoder": {
      "total": 2.567,
      "avg": 0.061119,
      "min": 0.060500,
      "max": 0.062000,
      "count": 42,
      "std": 0.000234
    },
    "channel": {
      "total": 1.890,
      "avg": 0.045000,
      "min": 0.044800,
      "max": 0.045300,
      "count": 42,
      "std": 0.000098
    },
    "decoder": {
      "total": 0.654,
      "avg": 0.015571,
      "min": 0.015400,
      "max": 0.015800,
      "count": 42,
      "std": 0.000067
    }
  },
  "percentages": {
    "source": 2.35,
    "encoder": 49.05,
    "channel": 36.12,
    "decoder": 12.48
  },
  "stages_total": 5.234,
  "overhead": 0.000
}
```

## Interpretaci√≥n de M√©tricas

### M√©tricas Generales

- **`total_time`**: Tiempo total de ejecuci√≥n del sistema (segundos)
- **`symbol_count`**: N√∫mero total de s√≠mbolos procesados
- **`throughput`**: Velocidad de procesamiento (s√≠mbolos/segundo)
- **`overhead`**: Tiempo no contabilizado en etapas (overhead del sistema)

### M√©tricas por Etapa

Para cada etapa (source, encoder, channel, decoder):

- **`total`**: Tiempo total de la etapa (segundos)
- **`avg`**: Tiempo promedio por s√≠mbolo (segundos/s√≠mbolo)
- **`min`**: Tiempo m√≠nimo registrado (segundos)
- **`max`**: Tiempo m√°ximo registrado (segundos)
- **`count`**: N√∫mero de veces que se ejecut√≥ la etapa
- **`std`**: Desviaci√≥n est√°ndar de los tiempos
- **`percentage`**: Porcentaje del tiempo total

## Generaci√≥n de Gr√°ficas

Para generar visualizaciones gr√°ficas del reporte:

```bash
cd /opt/OAM_System
python3 generate_profiling_graphs.py current_run/profiling_report.json current_run
```

Esto genera 4 archivos PNG:

1. **`profiling_bar_chart.png`** - Gr√°fica de barras con tiempos y porcentajes
2. **`profiling_pie_chart.png`** - Gr√°fica circular con distribuci√≥n
3. **`profiling_summary_table.png`** - Tabla resumen con todas las m√©tricas
4. **`profiling_timeline.png`** - L√≠nea de tiempo de ejecuci√≥n secuencial

### Ejemplo de Uso Completo

```bash
# 1. Ejecutar sistema con profiling
cd /opt/OAM_System
python3 oam_complete_system.py --headless --config current_run/config_from_grc.json

# 2. Verificar reporte JSON
cat current_run/profiling_report.json

# 3. Generar gr√°ficas
python3 generate_profiling_graphs.py

# 4. Ver gr√°ficas generadas
ls -lh current_run/profiling_*.png
```

## Salida en Consola

Al finalizar la ejecuci√≥n, el sistema imprime autom√°ticamente un resumen:

```
================================================================================
 REPORTE DE TIEMPOS DE EJECUCI√ìN - SISTEMA OAM
================================================================================

üìä RESUMEN GENERAL:
  ‚Ä¢ Tiempo total:        5.234 s
  ‚Ä¢ S√≠mbolos procesados: 42
  ‚Ä¢ Throughput:          8.02 s√≠mbolos/s
  ‚Ä¢ Overhead sistema:    0.000 s (0.0%)

‚è±Ô∏è  TIEMPOS POR ETAPA:
  Etapa           Total (s)    Promedio (s)    Min (s)    Max (s)    %
  --------------- ------------ --------------- ---------- ---------- --------
  SOURCE               0.123        0.002929   0.002800   0.003100      2.4%
  ENCODER              2.567        0.061119   0.060500   0.062000     49.0%
  CHANNEL              1.890        0.045000   0.044800   0.045300     36.1%
  DECODER              0.654        0.015571   0.015400   0.015800     12.5%

  TOTAL STAGES         5.234                                        100.0%

================================================================================
```

## An√°lisis de Rendimiento

### Etapa M√°s Lenta

Identificar la etapa que consume m√°s tiempo permite enfocar esfuerzos de optimizaci√≥n:

- **Encoder alto (>40%)** ‚Üí Optimizar generaci√≥n de haces LG
- **Channel alto (>40%)** ‚Üí Optimizar propagaci√≥n atmosf√©rica o reducir Ns
- **Decoder alto (>30%)** ‚Üí Optimizar correlaci√≥n NCC o usar cache de templates

### Throughput

El throughput indica cu√°ntos s√≠mbolos puede procesar el sistema por segundo:

- **> 10 sym/s** ‚Üí Rendimiento bueno para investigaci√≥n
- **5-10 sym/s** ‚Üí Rendimiento aceptable
- **< 5 sym/s** ‚Üí Considerar optimizaci√≥n

### Overhead

El overhead del sistema deber√≠a ser m√≠nimo (<5%):

- **< 1%** ‚Üí Excelente, casi todo el tiempo es procesamiento √∫til
- **1-5%** ‚Üí Aceptable
- **> 5%** ‚Üí Investigar causas (I/O, sincronizaci√≥n, etc.)

## Optimizaciones Sugeridas

Basado en los tiempos medidos:

### Si Encoder es el cuello de botella:

1. Usar cache de haces LG pre-generados
2. Reducir resoluci√≥n de grilla (`grid_size=256` en vez de `512`)
3. Vectorizar operaciones NumPy

### Si Channel es el cuello de botella:

1. Reducir n√∫mero de pantallas de fase (`Ns=1` en vez de `Ns>1`)
2. Optimizar FFT con algoritmos m√°s r√°pidos
3. Considerar GPU (CUDA/OpenCL)

### Si Decoder es el cuello de botella:

1. Implementar cache de templates LG
2. Usar correlaci√≥n parcial (sub-sampling)
3. Paralelizar detecci√≥n de modos

## Informaci√≥n de Contacto

**Autor:** Deiby Fernando Ariza Cadena
**Email:** deibyarizac@gmail.com
**Director:** Dr. Omar Javier Tijaro Rojas
**Instituci√≥n:** Universidad Industrial de Santander - Escuela E¬≥T

## Versi√≥n

- **Versi√≥n del Sistema:** OAM 1.0 (Production7)
- **Versi√≥n del Profiler:** 1.0.0
- **Fecha:** Enero 2025

---

Para m√°s informaci√≥n sobre el sistema OAM completo, consultar `README.md` en el directorio ra√≠z del proyecto.
